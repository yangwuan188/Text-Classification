{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:00:18.625532Z",
     "start_time": "2020-04-02T15:00:17.377733Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "from time import localtime, strftime\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "import zipfile\n",
    "import gc\n",
    "\n",
    "# fixing random seed for reproducibility\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Raw texts into training and development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reuters - Venezuelans turned out early\\and in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Reuters - South Korean police used water canno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Reuters - Thousands of Palestinian\\prisoners i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AFP - Sporadic gunfire and shelling took place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - Dozens of Rwandan soldiers flew into Suda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Reuters - Venezuelans turned out early\\and in ...\n",
       "1      1  Reuters - South Korean police used water canno...\n",
       "2      1  Reuters - Thousands of Palestinian\\prisoners i...\n",
       "3      1  AFP - Sporadic gunfire and shelling took place...\n",
       "4      1  AP - Dozens of Rwandan soldiers flew into Suda..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "data_tr = pd.read_csv('./data_topic/train.csv',header=None,names=['label','text'])\n",
    "data_dev = pd.read_csv('./data_topic/dev.csv',header=None,names=['label','text'])\n",
    "data_test = pd.read_csv('./data_topic/test.csv',header=None,names=['label','text'])\n",
    "data_tr.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_list = data_tr.text.tolist()\n",
    "dev_list = data_dev.text.tolist()\n",
    "test_list = data_test.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reuters - Venezuelans turned out early\\and in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Reuters - South Korean police used water canno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Reuters - Thousands of Palestinian\\prisoners i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AFP - Sporadic gunfire and shelling took place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - Dozens of Rwandan soldiers flew into Suda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Reuters - Rwandan troops were airlifted on Sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - A bomb exploded during an Independence Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>AFP - Australia's foreign minister will pay a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - Democratic presidential candidate John Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - Democratic vice presidential candidate Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>AFP - Although polls show the US presidential ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - Congress must pass legislation to protect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>AP - Missouri's attorney general sued the fede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>BAGHDAD (Reuters) - Insurgents fired mortars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>TOKYO (Reuters) - Three Japanese ministers pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Clashes between US troops and Sadr militiamen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>On Sunday, Venezuelans will decide whether to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Amid a reevaluation, officials this week pushe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Talks on setting up an Iraqi assembly continue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>A referendum is under way in Venezuela to deci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>An ailing Pope John Paul II says Mass at Lourd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>Rwandan troops arrive in Sudan to help protect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>Ian Thorpe sets the fastest time in the 200m f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>Iran's Arash Miresmaili withdraws from the Oly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>Santa Barbara's sheriff asks a judge if he can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>The Iraq crisis and differences over Nato loom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>Georgia and South Ossetia negotiate the detail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>The British journalist who was kidnapped in Ir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>A man convicted of raping and killing a school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter author JK Rowling delights a smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>3</td>\n",
       "      <td>Aug. 18 (Bloomberg) -- Andrew Mohl (left), chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>3</td>\n",
       "      <td>Nortel Networks is under investigation by the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>3</td>\n",
       "      <td>LOS ANGELES (Reuters) - Freddie Mac, the No. 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>3</td>\n",
       "      <td>Aug. 19 (Bloomberg) -- It #39;s time for the B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>3</td>\n",
       "      <td>Delta Air Lines #39; much-awaited turnaround p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>3</td>\n",
       "      <td>Reuters - Misconduct in the U.S. mutual fund\\i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>3</td>\n",
       "      <td>The productivity of America #39;s workers grew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>3</td>\n",
       "      <td>Credit Suisse Group, Switzerland #39;s second-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>3</td>\n",
       "      <td>Like the big oil companies, the world #39;s mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>3</td>\n",
       "      <td>Barclaycard, the UK #39;s largest credit card ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>3</td>\n",
       "      <td>CHICAGO (Reuters) - Medtronic Inc. (MDT.N: Quo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnson and Johnson is in negotiations to acqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>3</td>\n",
       "      <td>European Central Bank President Jean- Claude T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>3</td>\n",
       "      <td>IBM may need to do some creative deal making i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>3</td>\n",
       "      <td>Reuters - Freddie Mac (FRE.N), the No. 2 U.S.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>3</td>\n",
       "      <td>VEVEY, Switzerland Aug. 18, 2004  Nestle SA po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>3</td>\n",
       "      <td>SAN JOSE, Calif. (CP) - Google Inc. says its i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>3</td>\n",
       "      <td>Reuters - Google Inc.'s GOOG.O initial\\public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>3</td>\n",
       "      <td>SAN FRANCISCO (Reuters) - Google Inc.'s GOOG....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>3</td>\n",
       "      <td>China Mobile (Hong Kong), the world #39;s larg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>3</td>\n",
       "      <td>WASHINGTON (Reuters) - Freddie Mac (FRE.N: Quo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>3</td>\n",
       "      <td>MOUNTAIN VIEW, Calif. (AP)--Intuit Inc. #39;s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>3</td>\n",
       "      <td>TOKYO (Reuters) - Tokyo's Nikkei average adde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>3</td>\n",
       "      <td>If US Airways files for bankruptcy a second ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>3</td>\n",
       "      <td>Nortel Network Corp. #39;s board of directors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>3</td>\n",
       "      <td>Australia #39;s dominant airline, Qantas, has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>3</td>\n",
       "      <td>Reuters - Medtronic Inc. (MDT.N) on Wednesday\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>3</td>\n",
       "      <td>SAN FRANCISCO (Reuters) - Google Inc. &amp;lt;A H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>3</td>\n",
       "      <td>BHP Billiton, the world #39;s biggest mining c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>3</td>\n",
       "      <td>Europe’s Frustration Grows as Dollar Hits Anot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         1  Reuters - Venezuelans turned out early\\and in ...\n",
       "1         1  Reuters - South Korean police used water canno...\n",
       "2         1  Reuters - Thousands of Palestinian\\prisoners i...\n",
       "3         1  AFP - Sporadic gunfire and shelling took place...\n",
       "4         1  AP - Dozens of Rwandan soldiers flew into Suda...\n",
       "5         1  Reuters - Rwandan troops were airlifted on Sun...\n",
       "6         1  AP - A bomb exploded during an Independence Da...\n",
       "7         1  AFP - Australia's foreign minister will pay a ...\n",
       "8         1  AP - Democratic presidential candidate John Ke...\n",
       "9         1  AP - Democratic vice presidential candidate Jo...\n",
       "10        1  AFP - Although polls show the US presidential ...\n",
       "11        1  AP - Congress must pass legislation to protect...\n",
       "12        1  AP - Missouri's attorney general sued the fede...\n",
       "13        1   BAGHDAD (Reuters) - Insurgents fired mortars ...\n",
       "14        1   TOKYO (Reuters) - Three Japanese ministers pa...\n",
       "15        1  Clashes between US troops and Sadr militiamen ...\n",
       "16        1  On Sunday, Venezuelans will decide whether to ...\n",
       "17        1  Amid a reevaluation, officials this week pushe...\n",
       "18        1  Talks on setting up an Iraqi assembly continue...\n",
       "19        1  A referendum is under way in Venezuela to deci...\n",
       "20        1  An ailing Pope John Paul II says Mass at Lourd...\n",
       "21        1  Rwandan troops arrive in Sudan to help protect...\n",
       "22        1  Ian Thorpe sets the fastest time in the 200m f...\n",
       "23        1  Iran's Arash Miresmaili withdraws from the Oly...\n",
       "24        1  Santa Barbara's sheriff asks a judge if he can...\n",
       "25        1  The Iraq crisis and differences over Nato loom...\n",
       "26        1  Georgia and South Ossetia negotiate the detail...\n",
       "27        1  The British journalist who was kidnapped in Ir...\n",
       "28        1  A man convicted of raping and killing a school...\n",
       "29        1  Harry Potter author JK Rowling delights a smal...\n",
       "...     ...                                                ...\n",
       "2370      3  Aug. 18 (Bloomberg) -- Andrew Mohl (left), chi...\n",
       "2371      3  Nortel Networks is under investigation by the ...\n",
       "2372      3  LOS ANGELES (Reuters) - Freddie Mac, the No. 2...\n",
       "2373      3  Aug. 19 (Bloomberg) -- It #39;s time for the B...\n",
       "2374      3  Delta Air Lines #39; much-awaited turnaround p...\n",
       "2375      3  Reuters - Misconduct in the U.S. mutual fund\\i...\n",
       "2376      3  The productivity of America #39;s workers grew...\n",
       "2377      3  Credit Suisse Group, Switzerland #39;s second-...\n",
       "2378      3  Like the big oil companies, the world #39;s mi...\n",
       "2379      3  Barclaycard, the UK #39;s largest credit card ...\n",
       "2380      3  CHICAGO (Reuters) - Medtronic Inc. (MDT.N: Quo...\n",
       "2381      3  Johnson and Johnson is in negotiations to acqu...\n",
       "2382      3  European Central Bank President Jean- Claude T...\n",
       "2383      3  IBM may need to do some creative deal making i...\n",
       "2384      3  Reuters - Freddie Mac (FRE.N), the No. 2 U.S.\\...\n",
       "2385      3  VEVEY, Switzerland Aug. 18, 2004  Nestle SA po...\n",
       "2386      3  SAN JOSE, Calif. (CP) - Google Inc. says its i...\n",
       "2387      3  Reuters - Google Inc.'s GOOG.O initial\\public ...\n",
       "2388      3   SAN FRANCISCO (Reuters) - Google Inc.'s GOOG....\n",
       "2389      3  China Mobile (Hong Kong), the world #39;s larg...\n",
       "2390      3  WASHINGTON (Reuters) - Freddie Mac (FRE.N: Quo...\n",
       "2391      3  MOUNTAIN VIEW, Calif. (AP)--Intuit Inc. #39;s ...\n",
       "2392      3   TOKYO (Reuters) - Tokyo's Nikkei average adde...\n",
       "2393      3  If US Airways files for bankruptcy a second ti...\n",
       "2394      3  Nortel Network Corp. #39;s board of directors ...\n",
       "2395      3  Australia #39;s dominant airline, Qantas, has ...\n",
       "2396      3  Reuters - Medtronic Inc. (MDT.N) on Wednesday\\...\n",
       "2397      3   SAN FRANCISCO (Reuters) - Google Inc. &lt;A H...\n",
       "2398      3  BHP Billiton, the world #39;s biggest mining c...\n",
       "2399      3  Europe’s Frustration Grows as Dollar Hits Anot...\n",
       "\n",
       "[2400 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:40.851926Z",
     "start_time": "2020-04-02T14:26:40.847500Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = ['a','in','on','at','and','or', \n",
    "              'to', 'the', 'of', 'an', 'by', \n",
    "              'as', 'is', 'was', 'were', 'been', 'be', \n",
    "              'are','for', 'this', 'that', 'these', 'those', 'you', 'i', 'if',\n",
    "             'it', 'he', 'she', 'we', 'they', 'will', 'have', 'has',\n",
    "              'do', 'did', 'can', 'could', 'who', 'which', 'what',\n",
    "              'but', 'not', 'there', 'no', 'does', 'not', 'so', 've', 'their',\n",
    "             'his', 'her', 'they', 'them', 'from', 'with', 'its']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram extraction from a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:41.505459Z",
     "start_time": "2020-04-02T14:26:41.498388Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_ngrams(x_raw, ngram_range=(1,3), token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b', stop_words=[], vocab=set()):\n",
    "    #extract all tokens\n",
    "    import re\n",
    "    x_raw1 = re.findall(token_pattern , x_raw)\n",
    "    for i in range(len(x_raw1)):          ##########lower\n",
    "        x_raw1[i]=x_raw1[i].lower()\n",
    "#########remove stop_words\n",
    "    if stop_words:\n",
    "        x_raw2 = x_raw1.copy()\n",
    "        for i in range(0,len(x_raw1)):\n",
    "            if x_raw1[i] in stop_words: \n",
    "                x_raw2.remove(x_raw1[i])\n",
    "        x_raw1 = x_raw2\n",
    "#########ngram_range\n",
    "    word_extract = []\n",
    "    begin = ngram_range[0]\n",
    "    end = ngram_range[1]\n",
    "    rangenumber = [] #save range value\n",
    "    for i in range(begin,end+1):\n",
    "        rangenumber.append(i)\n",
    "        i+=1\n",
    "    # #Judge whether range is appropriate\n",
    "    if len(x_raw1)<begin:\n",
    "        print(\"Minimum of range is too large\")\n",
    "    elif len(x_raw1)<end:\n",
    "        print(\"Maximum range is too large\")\n",
    "    elif len(x_raw1)>=begin and len(x_raw1)>=end:\n",
    "        for j in rangenumber:\n",
    "            for ii in range(0,len(x_raw1)):\n",
    "                temp = []\n",
    "                if j==1:\n",
    "                    word_extract.append(x_raw1[ii])\n",
    "                else:\n",
    "                    for num in range (0,j):             \n",
    "                        if ii+(j-1) <len(x_raw1):\n",
    "                            temp.append(x_raw1[ii+num])\n",
    "                    if len(temp) !=0:\n",
    "                        word_extract.append(tuple(temp))\n",
    "#########vocab\n",
    "    if len(vocab) != 0:\n",
    "        word_vocab = []\n",
    "        for i in vocab:\n",
    "            for j in word_extract:\n",
    "                if i == j:\n",
    "                    word_vocab.append(i)      \n",
    "        x = word_vocab\n",
    "        return x \n",
    "    x = word_extract\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocabulary of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:42.563876Z",
     "start_time": "2020-04-02T14:26:42.557967Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vocab(X_raw, ngram_range=(1,3), token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b', \n",
    "              min_df=0, keep_topN=0, stop_words=[]):\n",
    "    doc_text = []\n",
    "    for i in X_raw:\n",
    "        text = extract_ngrams(i, ngram_range, token_pattern , stop_words)\n",
    "        text_de = sorted(set(text), key = text.index) #deduplication\n",
    "        doc_text.append(text_de)\n",
    "   \n",
    "    word_ngram_df = {} #dic to save the ngram with df\n",
    "    vocab=[]\n",
    "    ngram_counts = []\n",
    "    #count frequency\n",
    "    for doc in doc_text: #every doc text  \n",
    "        for ngram in doc: #every ngram in each document\n",
    "            if ngram in word_ngram_df.keys():\n",
    "                value = word_ngram_df[ngram]\n",
    "                word_ngram_df[ngram] = value+1 \n",
    "            \n",
    "            elif ngram not in word_ngram_df.keys(): #dictionary initialization\n",
    "                word_ngram_df[ngram]=1\n",
    "          \n",
    "\n",
    "    for key,value in word_ngram_df.items():  #delet minimum df ngram\n",
    "        if value < min_df:\n",
    "            del word_ngram_df[key]\n",
    "\n",
    "    vocab_dic_list = sorted(word_ngram_df.items(),key=lambda x:x[1],reverse=True) #sort:large to low\n",
    "    \n",
    "    vocab_dic = Counter() #Counter\n",
    "    for ngram ,value in vocab_dic_list:\n",
    "         if ngram not in vocab_dic.keys():\n",
    "                vocab_dic[ngram]=value\n",
    "                \n",
    "    count2=0   #save top N more frequent ngrams if =0 will keep all the ngrams\n",
    "    for key , value in vocab_dic.items():\n",
    "        count2+=1\n",
    "        if count2 > keep_topN and keep_topN!=0:\n",
    "            break\n",
    "        vocab.append(key) \n",
    "        ngram_counts.append(value)  \n",
    "    df = vocab_dic\n",
    "    return vocab, df, ngram_counts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `get_vocab` to create your vocabulary and get document and raw frequencies of unigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:43.577997Z",
     "start_time": "2020-04-02T14:26:43.478950Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "\n",
      "['reuters', 'said', 'tuesday', 'wednesday', 'new', 'after', 'ap', 'athens', 'monday', 'first', 'two', 'york', 'over', 'us', 'olympic', 'inc', 'more', 'year', 'oil', 'prices', 'company', 'world', 'than', 'aug', 'about', 'had', 'united', 'one', 'out', 'sunday', 'into', 'against', 'up', 'second', 'last', 'president', 'stocks', 'gold', 'team', 'when', 'three', 'night', 'time', 'yesterday', 'games', 'olympics', 'states', 'greece', 'off', 'iraq', 'washington', 'percent', 'home', 'day', 'google', 'public', 'record', 'week', 'men', 'government', 'win', 'american', 'won', 'years', 'all', 'billion', 'shares', 'city', 'offering', 'officials', 'would', 'today', 'final', 'afp', 'gt', 'people', 'lt', 'medal', 'corp', 'sales', 'country', 'back', 'four', 'high', 'investor', 'com', 'minister', 'reported', 'month', 'initial', 'profit', 'ticker', 'al', 'million', 'top', 'before', 'china', 'him', 'national', 'najaf']\n",
      "\n",
      "[('reuters', 631), ('said', 432), ('tuesday', 413), ('wednesday', 344), ('new', 325), ('after', 295), ('ap', 275), ('athens', 245), ('monday', 221), ('first', 210)]\n"
     ]
    }
   ],
   "source": [
    "vocab, df, ngram_counts = get_vocab(tr_list, ngram_range=(1,1), keep_topN=2000, stop_words=stop_words)\n",
    "print(len(vocab))\n",
    "print()\n",
    "print(list(vocab)[:100])\n",
    "print()\n",
    "print(df.most_common()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vocabulary id -> word and id -> word dictionaries for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:44.069661Z",
     "start_time": "2020-04-02T14:26:44.065058Z"
    }
   },
   "outputs": [],
   "source": [
    "def vocab_dict(X_raw, ngram_range=(1,3), token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b', min_df=0, keep_topN=0, stop_words=[]):\n",
    "    vocab, df, ngram_counts = get_vocab(X_raw, ngram_range=ngram_range, token_pattern=token_pattern, min_df=min_df, keep_topN=keep_topN, stop_words=stop_words)\n",
    "    vocab_dict = dict()\n",
    "    for i in range (1,len(vocab)+1):\n",
    "        vocab_dict[i]=vocab[i-1]\n",
    "    return vocab_dict\n",
    "\n",
    "MIN_DF = 0\n",
    "KEEP_TOPN = 2000 #if set =0 will keep all the n-grams\n",
    "Token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b'\n",
    "Ngram_range=(1,1)\n",
    "\n",
    "#sentiment task1     ##keep_topN should be set bigger than 0\n",
    "data_tr_vocab_dict = vocab_dict(tr_list, ngram_range=Ngram_range, token_pattern=Token_pattern, min_df=MIN_DF, keep_topN=KEEP_TOPN, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reuters'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr_vocab_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the list of unigrams  into a list of vocabulary indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:45.047887Z",
     "start_time": "2020-04-02T14:26:44.920631Z"
    }
   },
   "outputs": [],
   "source": [
    "def Extract_ngrams(X_raw, ngram_range=(1,1), token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b', min_df=0, keep_topN=0, stop_words=[],vocab=set()):\n",
    "    doc_text = []\n",
    "    for i in X_raw:\n",
    "        text = extract_ngrams(i, ngram_range, token_pattern , stop_words , vocab)\n",
    "        doc_text.append(text)\n",
    "    return doc_text\n",
    "\n",
    "Vocab = set()\n",
    "Keep_topN= 2000\n",
    "Token_pattern=r'\\b[A-Za-z][A-Za-z]+\\b'\n",
    "Ngram_range=(1,1) #only word\n",
    "#lists of words\n",
    "X_tr_ext = Extract_ngrams(tr_list, ngram_range=Ngram_range, token_pattern=Token_pattern,keep_topN = Keep_topN, stop_words=stop_words, vocab=Vocab)\n",
    "X_dev_ext = Extract_ngrams(dev_list, ngram_range=Ngram_range, token_pattern=Token_pattern,keep_topN = Keep_topN,stop_words=stop_words, vocab=Vocab)\n",
    "X_test_ext = Extract_ngrams(test_list, ngram_range=Ngram_range, token_pattern=Token_pattern,keep_topN = Keep_topN, stop_words=stop_words, vocab=Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retain the words in vocabulary (vocab list)\n",
    "import copy\n",
    "def ugrams_vocab(X_ugrams,vocab):\n",
    "    new_X_ugrams = copy.deepcopy(X_ugrams)\n",
    "    for i in range(len(X_ugrams)): #every documents\n",
    "        for j in X_ugrams[i]:  #every words\n",
    "            if j not in vocab:\n",
    "                new_X_ugrams[i].remove(j)\n",
    "    return new_X_ugrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep all the words in the vocabulary\n",
    "X_uni_tr=ugrams_vocab(X_tr_ext,vocab)  \n",
    "X_uni_dev=ugrams_vocab(X_dev_ext,vocab)\n",
    "X_uni_test=ugrams_vocab(X_test_ext,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reuters',\n",
       " 'venezuelans',\n",
       " 'turned',\n",
       " 'out',\n",
       " 'early',\n",
       " 'large',\n",
       " 'numbers',\n",
       " 'sunday',\n",
       " 'vote',\n",
       " 'historic',\n",
       " 'referendum',\n",
       " 'either',\n",
       " 'left',\n",
       " 'wing',\n",
       " 'president',\n",
       " 'hugo',\n",
       " 'chavez',\n",
       " 'office',\n",
       " 'give',\n",
       " 'him',\n",
       " 'new',\n",
       " 'mandate',\n",
       " 'next',\n",
       " 'two',\n",
       " 'years']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_uni_tr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then convert them into lists of indices in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:45.752658Z",
     "start_time": "2020-04-02T14:26:45.730409Z"
    }
   },
   "outputs": [],
   "source": [
    "new_dict = copy.deepcopy(data_tr_vocab_dict)\n",
    "new_dict = {v : k for k, v in new_dict.items()}\n",
    "\n",
    "def Indices(X_raw, vocab_dict):\n",
    "    X_indices = copy.deepcopy(X_raw)\n",
    "    \n",
    "    for i in range(len(X_raw)):\n",
    "        for j in range(len(X_raw[i])):\n",
    "            X_indices[i][j] = new_dict[X_raw[i][j]]\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = Indices(X_uni_tr,new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1012,\n",
       " 759,\n",
       " 29,\n",
       " 209,\n",
       " 1104,\n",
       " 1368,\n",
       " 30,\n",
       " 309,\n",
       " 817,\n",
       " 263,\n",
       " 1587,\n",
       " 109,\n",
       " 760,\n",
       " 36,\n",
       " 173,\n",
       " 176,\n",
       " 494,\n",
       " 702,\n",
       " 98,\n",
       " 5,\n",
       " 1222,\n",
       " 174,\n",
       " 11,\n",
       " 64]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_uni_dev\n",
    "X_dev = Indices(X_uni_dev,new_dict)\n",
    "X_test = Indices(X_uni_test,new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the labels `Y` for train, dev and test sets into arrays: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:03:13.183996Z",
     "start_time": "2020-04-02T15:03:13.077575Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_tr = np.array(data_tr.label)\n",
    "Y_dev = np.array(data_dev.label)\n",
    "Y_test = np.array(data_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:09:10.086665Z",
     "start_time": "2020-04-02T15:09:10.083429Z"
    }
   },
   "outputs": [],
   "source": [
    "def network_weights(vocab_size=1000, embedding_dim=300, \n",
    "                    hidden_dim=[], num_classes=3, init_val = 0.5):\n",
    "    W = {}\n",
    "    L = len(hidden_dim) #number of hidden layers\n",
    "    \n",
    "    #input layer  vocab_size * embedding_dim\n",
    "    W[0] = ((init_val*np.random.uniform(-1.0,1.0,(vocab_size,embedding_dim))).astype(np.float32))\n",
    "    if L !=0: #hidden layer\n",
    "        W[1] = ((init_val*np.random.uniform(-1.0,1.0,(embedding_dim,hidden_dim[0]))).astype(np.float32))\n",
    "        for i in range(1,L):\n",
    "            W[i+1] = ((init_val*np.random.uniform(-1.0,1.0,(hidden_dim[i-1],hidden_dim[i]))).astype(np.float32))\n",
    "            #output layer  last hidden_dim*num_classes\n",
    "        W[L+1] = ((init_val*np.random.uniform(-1.0,1.0,(hidden_dim[L-1],num_classes))).astype(np.float32))\n",
    "    else:\n",
    "        #output layer without hidden layer  embedding_dim*num+classes\n",
    "        W[1] =  ((init_val*np.random.uniform(-1.0,1.0,(embedding_dim,num_classes))).astype(np.float32))\n",
    "    return W\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:48.636732Z",
     "start_time": "2020-04-02T14:26:48.634122Z"
    }
   },
   "outputs": [],
   "source": [
    "W = network_weights(vocab_size=3,embedding_dim=4,hidden_dim=[2], num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_emb: (3, 4)\n",
      "W_h1: (4, 2)\n",
      "W_out: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "print('W_emb:', W[0].shape)\n",
    "print('W_h1:', W[1].shape)\n",
    "print('W_out:', W[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:50.504086Z",
     "start_time": "2020-04-02T14:26:50.500686Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    sig = (np.exp(z).T/np.sum(np.exp(z))).T\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:51.360838Z",
     "start_time": "2020-04-02T14:26:51.356935Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_loss(y, y_preds):  \n",
    "    l =  -np.log(y_preds)\n",
    "    l = l[y]   \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.40802648 1.30802648 1.40802648 3.60802648 0.80802648]\n",
      "y_preds:  [0.01217919 0.27035308 0.24462558 0.02710529 0.44573687]\n",
      "log y_preds [4.40802648 1.30802648 1.40802648 3.60802648 0.80802648]\n",
      "loss: 1.40802648485675\n"
     ]
    }
   ],
   "source": [
    "y = 2 #true label\n",
    "y_preds = softmax(np.array([[-2.1,1.,0.9,-1.3,1.5]]))[0]\n",
    "print(-np.log(y_preds))\n",
    "print('y_preds: ',y_preds)\n",
    "print('log y_preds',-np.log(y_preds))\n",
    "print('loss:', categorical_loss(y, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:52.665236Z",
     "start_time": "2020-04-02T14:26:52.661519Z"
    }
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    a = z.copy()\n",
    "    a=np.maximum(a,0)         \n",
    "    return a\n",
    "    \n",
    "def relu_derivative(z):\n",
    "    dz = z.copy()\n",
    "    dz = np.array(dz)\n",
    "    dz[dz<=0]=0\n",
    "    dz[dz>0]=1\n",
    "    \n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:53.429192Z",
     "start_time": "2020-04-02T14:26:53.425301Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def dropout_mask(size, dropout_rate):\n",
    "    dropout_vec = np.ones(size)\n",
    "    #random.seed (33)# should i set the random seed?\n",
    "    num_zero = int(dropout_rate*size)#get number of 0\n",
    "    index = list(range(size)) ##index list of the droput\n",
    "    random_index = random.sample(index,num_zero) #random select the index of 0\n",
    "\n",
    "    for i in random_index:#set 0\n",
    "        dropout_vec[i] = 0     \n",
    "    return dropout_vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:53.853632Z",
     "start_time": "2020-04-02T14:26:53.849944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(dropout_mask(10, 0.2))\n",
    "print(dropout_mask(10, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward_pass` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:26:54.761268Z",
     "start_time": "2020-04-02T14:26:54.753402Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_pass(x, W, dropout_rate=0.2):\n",
    "    out_vals = {}\n",
    "    h_vecs = []\n",
    "    a_vecs = []\n",
    "    dropout_vecs = []\n",
    "    num=len(W)\n",
    "    X=np.zeros((len(W[0]),1)) #x , y go to vector\n",
    "    for i in x:\n",
    "        X[i-1] = 1\n",
    "    h1 = (np.dot(X.T,W[0]))/len(X)\n",
    "    h_vecs.append(h1.squeeze())\n",
    "    a0 = relu(h1)\n",
    "    a_vecs.append(a0.squeeze())\n",
    "    dp = dropout_mask(a0.shape[1],dropout_rate)\n",
    "    dropout_vecs.append(dp.squeeze())\n",
    "    a=a0*dp #a*dropout before sent to next\n",
    "    for i in range(1,num-1):\n",
    "        h = np.dot(a,W[i])\n",
    "        h_vecs.append(h.squeeze())\n",
    "        a = relu(h)\n",
    "        a_vecs.append(a.squeeze())\n",
    "        dp = dropout_mask(a.shape[1],dropout_rate)\n",
    "        dropout_vecs.append(dp.squeeze())\n",
    "        a=a*dp #a*dropout before sent to next\n",
    "    #output layer\n",
    "    y = softmax(np.dot(a,W[num-1]))\n",
    "    \n",
    "    out_vals['h']=h_vecs\n",
    "    out_vals['a']=a_vecs\n",
    "    out_vals['dropout_vec']=dropout_vecs\n",
    "    out_vals['y']= y.squeeze()\n",
    "    \n",
    "    return out_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape W0 (3, 4)\n",
      "Shape W1 (4, 5)\n",
      "Shape W2 (5, 3)\n",
      "Shape W3 (3, 2)\n",
      "\n",
      "{'h': [array([ 0.00538581, -0.01535499, -0.18203547, -0.11267853]), array([0., 0., 0., 0., 0.]), array([0., 0., 0.])], 'a': [array([0.00538581, 0.        , 0.        , 0.        ]), array([0., 0., 0., 0., 0.]), array([0., 0., 0.])], 'dropout_vec': [array([0., 1., 0., 1.]), array([0., 1., 1., 0., 1.]), array([1., 1., 0.])], 'y': array([0.5, 0.5])}\n"
     ]
    }
   ],
   "source": [
    "W = network_weights(vocab_size=3,embedding_dim=4,hidden_dim=[5,3], num_classes=2)\n",
    "\n",
    "for i in range(len(W)):\n",
    "    print('Shape W'+str(i), W[i].shape)\n",
    "\n",
    "print()\n",
    "print(forward_pass([2,1], W, dropout_rate=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(x, y, W, out_vals, lr=0.001, freeze_emb=False):\n",
    "    \n",
    "    y_pre = out_vals['y']\n",
    "    list_a = out_vals['a']  #the stored value is the next layer a =(a*dropout)\n",
    "    list_h = out_vals['h']\n",
    "    list_droput = out_vals['dropout_vec']\n",
    "    X=np.zeros((len(W[0]),1))\n",
    "    for i in x:\n",
    "        X[i-1] = 1\n",
    "    Y = np.zeros((1,3))\n",
    "    Y[0][y-1] = 1\n",
    "    lenw = len(W) \n",
    "#######output layer\n",
    "    L_g = y_pre - Y\n",
    "    dw = np.dot((list_a[-1]*list_droput[-1]).reshape([W[lenw-1].shape[0],1]), L_g.reshape([1,W[lenw-1].shape[1]]))#g2*a1\n",
    "    g = np.dot(W[len(W)-1],L_g.T ).reshape([W[lenw-1].shape[0],1])\n",
    "    W[lenw-1] -= lr * dw  \n",
    "    \n",
    "    i=0\n",
    "    for i in range(lenw-2): #hidden layer\n",
    "        g_in = g                            #g hk-1\n",
    "        g =  g_in * relu_derivative((list_h[lenw-2-i].reshape([W[lenw-1-i].shape[0],1])))\n",
    "        dw = np.dot((list_a[lenw-3-i]*list_droput[lenw-3-i]).reshape([W[lenw-2-i].shape[0],1]),g.T) # 300x1 1x5 300x5\n",
    "        g = np.dot(W[lenw-2-i],g)\n",
    "        W[lenw-2-i] -= lr*dw\n",
    "            \n",
    "        if freeze_emb ==False:\n",
    "          # # print('h0',list_h[0].reshape([W[0].shape[1],1]).shape,'transa',g.shape,'x',X.shape)\n",
    "            g =  g *relu_derivative(list_h[0]).reshape([W[0].shape[1],1])\n",
    "            dw = np.dot( X,g.T)\n",
    "            W[0] -= lr* dw\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:09:19.021428Z",
     "start_time": "2020-04-02T15:09:19.017835Z"
    }
   },
   "outputs": [],
   "source": [
    "def SGD(X_tr, Y_tr, W, X_dev=[], Y_dev=[], lr=0.001, \n",
    "        dropout=0.2, epochs=5, tolerance=0.001, freeze_emb=False, print_progress=True):\n",
    "    \n",
    "    Weight = W\n",
    "    cur_loss_tr = 1.\n",
    "    cur_loss_dev = 1.\n",
    "    training_loss_history = []\n",
    "    validation_loss_history = []\n",
    "    \n",
    "    XX_tr = copy.deepcopy(X_tr)\n",
    "    YY_tr = copy.deepcopy(Y_tr)\n",
    "    for e in range (0,epochs):  \n",
    "        Weight= Weight\n",
    "        list_loss_tr= []\n",
    "        list_loss_dev = []\n",
    "        #randomise order in every epoch\n",
    "        c = list(zip(XX_tr,YY_tr))\n",
    "        np.random.shuffle(c)\n",
    "        XX_tr,YY_tr = zip(*c)\n",
    "        num = len(XX_tr) #2400\n",
    "\n",
    "        for i in range (0,num):\n",
    "            x = XX_tr[i] #doc \n",
    "            y = YY_tr[i]\n",
    "            layer_outputs = forward_pass( x, Weight ,dropout )\n",
    "            # print(layer_outputs)\n",
    "            Weight = backward_pass(x, y, Weight,layer_outputs , lr ,freeze_emb=freeze_emb)\n",
    "        #compute loss in train\n",
    "        for ii in range(0,num):\n",
    "            x = XX_tr[ii]\n",
    "            y = YY_tr[ii]\n",
    "            layer_outputs = forward_pass( x,Weight ,dropout )\n",
    "            y_pre = layer_outputs['y']\n",
    "          #  print('label',y)\n",
    "          #  print('y_pre ',y_pre)\n",
    "            list_loss_tr.append(categorical_loss(y-1, y_pre))    \n",
    "        loss_tr = np.mean(list_loss_tr)\n",
    "        #compute loss in dev\n",
    "        num1 = len(X_dev)\n",
    "        for j in range (0,num1):\n",
    "            x = X_dev[j]\n",
    "            y = Y_dev[j]\n",
    "            layer_outputs = forward_pass( x,Weight ,dropout )\n",
    "            y_pre = layer_outputs['y']\n",
    "            list_loss_dev.append(categorical_loss(y-1,y_pre))     \n",
    "        loss_dev = np.mean(list_loss_dev)\n",
    "        \n",
    "        diff_tr_loss = cur_loss_tr - loss_tr\n",
    "        cur_loss_tr = loss_tr\n",
    "        diff_dev_loss = cur_loss_dev - loss_dev\n",
    "        cur_loss_dev = loss_dev\n",
    "        \n",
    "        training_loss_history.append(loss_tr)\n",
    "        validation_loss_history.append(loss_dev)\n",
    "        if print_progress == True:\n",
    "            print(\"Epoch:\", e ,\"| Training loss: \",loss_tr ,\"| Validation loss:\", loss_dev)\n",
    "        if abs(diff_dev_loss) < tolerance :\n",
    "            break  \n",
    "\n",
    "    W= Weight\n",
    "    \n",
    "    return W, training_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:09:33.643515Z",
     "start_time": "2020-04-02T15:09:33.640943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab 2000\n",
      "Shape W0 (2000, 300)\n",
      "Shape W1 (300, 5)\n",
      "Shape W2 (5, 3)\n",
      "Epoch: 0 | Training loss:  1.0985479306932306 | Validation loss: 1.0986053686501758\n",
      "Epoch: 1 | Training loss:  1.0984741404951626 | Validation loss: 1.0985079283860797\n"
     ]
    }
   ],
   "source": [
    "W = network_weights(vocab_size=len(vocab),embedding_dim=300,hidden_dim=[5], num_classes=3)\n",
    "print('Length of vocab',len(vocab))\n",
    "for i in range(len(W)):\n",
    "    print('Shape W'+str(i), W[i].shape)\n",
    "\n",
    "W, loss_tr, dev_loss = SGD(X_tr, Y_tr,\n",
    "                            W,\n",
    "                            X_dev=X_dev, \n",
    "                            Y_dev=Y_dev,\n",
    "                            lr=0.002, \n",
    "                            dropout=0.5,\n",
    "                            freeze_emb=False,\n",
    "                            tolerance=0.001,\n",
    "                            epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:27:15.716497Z",
     "start_time": "2020-04-02T14:27:15.612736Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangwuan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure()\n",
    "fig.suptitle('Training Monitoring')\n",
    "x = range(0,len(loss_tr))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x,loss_tr, label=\"training loss\")\n",
    "plt.plot(x,dev_loss, label=\"validation loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy, precision, recall and F1-Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:10:11.037495Z",
     "start_time": "2020-04-02T15:10:11.034999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "Precision: 0.5697998644210419\n",
      "Recall: 0.48\n",
      "F1-Score: 0.4466374149051193\n"
     ]
    }
   ],
   "source": [
    "preds_te = [np.argmax(forward_pass(x, W, dropout_rate=0.0)['y'])+1 for x,y in zip(X_test,Y_test)] \n",
    "#print(preds_te)  #Because in my forward pass the pre_y is the index of y so need to add1\n",
    "print('Accuracy:', accuracy_score(Y_test,preds_te))\n",
    "print('Precision:', precision_score(Y_test,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(Y_test,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(Y_test,preds_te,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss how did you choose model hyperparameters ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      The total length of the original vocab was about 8000, and the word number in x (each document) in the training set was relatively small. Therefore,lr=0.02, vocab_size = 2000, dropout=0.3, embedding_dim remained unchanged, and hidden_dim was set to a single layer of 5, which ensured fast computing speed and good results(tolerance=0.005,epochs=20)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pre-trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_tr_vocab_dict is id->word dict           #2000 WORDS\n",
    "new_dict = data_tr_vocab_dict.copy()  #key is from 1   change to word2id need from 0\n",
    "zip(new_dict.values(), new_dict.keys())\n",
    "word2id = dict(zip(new_dict.values(), new_dict.keys()))\n",
    "for k in word2id: #change index \n",
    "    word2id[k]-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:27:32.020697Z",
     "start_time": "2020-04-02T14:27:32.015733Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_glove_embeddings(f_zip, f_txt, word2id, emb_size=300):\n",
    "    \n",
    "    w_emb = np.zeros((len(word2id), emb_size))\n",
    "    \n",
    "    with zipfile.ZipFile(f_zip) as z:\n",
    "        with z.open(f_txt) as f:\n",
    "            for line in f:\n",
    "                line = line.decode('utf-8')\n",
    "                word = line.split()[0]\n",
    "                     \n",
    "                if word in vocab:\n",
    "                    emb = np.array(line.strip('\\n').split()[1:]).astype(np.float32)\n",
    "                    w_emb[word2id[word]] +=emb\n",
    "    return w_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:28:54.548613Z",
     "start_time": "2020-04-02T14:27:32.780248Z"
    }
   },
   "outputs": [],
   "source": [
    "w_glove = get_glove_embeddings(\"glove.840B.300d.zip\",\"glove.840B.300d.txt\",word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:30:11.121198Z",
     "start_time": "2020-04-02T14:29:24.946124Z"
    }
   },
   "outputs": [],
   "source": [
    "w_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = network_weights(vocab_size=len(vocab),embedding_dim=300,hidden_dim=[5], num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W[0]=w_glove.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of vocab',len(vocab))\n",
    "for i in range(len(W)):\n",
    "    print('Shape W'+str(i), W[i].shape)\n",
    "\n",
    "W, loss_tr, dev_loss = SGD(X_tr, Y_tr,\n",
    "                            W,\n",
    "                            X_dev=X_dev, \n",
    "                            Y_dev=Y_dev,\n",
    "                            lr=0.01, \n",
    "                            dropout=0.3,\n",
    "                            freeze_emb=True,\n",
    "                            tolerance=0.0001,\n",
    "                            epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:12:00.815184Z",
     "start_time": "2020-04-02T15:12:00.812563Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_te = [np.argmax(forward_pass(x, W, dropout_rate=0.0)['y'])+1 for x,y in zip(X_test,Y_test)]\n",
    "print('Accuracy:', accuracy_score(Y_test,preds_te))\n",
    "print('Precision:', precision_score(Y_test,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(Y_test,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(Y_test,preds_te,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss how did you choose model hyperparameters ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The prepared W makes the training loss very small and close to the optimal value at the beginning, so I reduce the learning rate to other invariable quick fitting. lr = 0.01 (from 0.05), vocab_size = 2000, dropout=0.3, embedding_dim remained unchanged. Accuracy improved by one or two percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend to support deeper architectures (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:58:51.764619Z",
     "start_time": "2020-04-02T14:58:47.483690Z"
    }
   },
   "outputs": [],
   "source": [
    "WW = w_glove.copy()\n",
    "W = network_weights(vocab_size=len(vocab),embedding_dim=300,hidden_dim=[100,10], num_classes=3)\n",
    "W[0]=WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of vocab',len(vocab))\n",
    "for i in range(len(W)):\n",
    "    print('Shape W'+str(i), W[i].shape)\n",
    "\n",
    "W, loss_tr, dev_loss = SGD(X_tr, Y_tr,\n",
    "                            W,\n",
    "                            X_dev=X_dev, \n",
    "                            Y_dev=Y_dev,\n",
    "                            lr=0.02, \n",
    "                            dropout=0.3,\n",
    "                            freeze_emb=True,\n",
    "                            tolerance=0.005,\n",
    "                            epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T15:11:51.994986Z",
     "start_time": "2020-04-02T15:11:51.992563Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_te = [np.argmax(forward_pass(x, W, dropout_rate=0.0)['y'])+1 for x,y in zip(X_test,Y_test)]\n",
    "print('Accuracy:', accuracy_score(Y_test,preds_te))\n",
    "print('Precision:', precision_score(Y_test,preds_te,average='macro'))\n",
    "print('Recall:', recall_score(Y_test,preds_te,average='macro'))\n",
    "print('F1-Score:', f1_score(Y_test,preds_te,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Results\n",
    "\n",
    "Add your final results here:\n",
    "\n",
    "| Model | Precision  | Recall  | F1-Score  | Accuracy\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "| Average Embedding  | 0.8476  | 0.8388  |  0.8391 | 0.8388  |\n",
    "| Average Embedding (Pre-trained)  | 0.8565  | 0.8533  | 0.8541  |  0.8533 |\n",
    "| Average Embedding (Pre-trained) + X hidden layers (BONUS)   |  0.8551 | 0.8488  | 0.8491  | 0.8488  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Hidden layers are set to [100,10] was added, but the training was slower and the score hardly improved. If the learning rate was further increased, loss would fluctuate greatly and nan would easily appear. Therefore, the learning rate =0.02.For the network, increasing the hidden layer may not be as good as fewer hidden layers and appropriate parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
